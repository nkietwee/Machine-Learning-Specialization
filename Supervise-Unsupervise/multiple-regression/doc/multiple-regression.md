## Multiple regresion
---

# üîç Overview: Multiple Linear Regression

- In the earlier version of linear regression, we used only **one feature** (e.g., size of the house) to predict the output (e.g., price of the house). but for **Multiple Linear Regression** we use **multiple feature**  such as:
Size of the house (`x‚ÇÅ`), Number of bedrooms (`x‚ÇÇ`), Number of floors (`x‚ÇÉ`) and Age of the house (`x‚ÇÑ`) for predict output value


### üìö Notation
# üìä Multiple Features (Variables)


| Size in feet¬≤ (ùë•‚ÇÅ) | Number of bedrooms (ùë•‚ÇÇ) | Number of floors (ùë•‚ÇÉ) | Age of home in years (ùë•‚ÇÑ) | Price ($1000's) |
|:------------------:|:------------------------:|:----------------------:|:--------------------------:|:----------------:|
|       2104         |            5             |           1            |            45              |       460        |
|       1416         |            3             |           2            |            40       f‡∏î       |       232        |
|       1534         |            3             |           2            |            30              |       315        |
|        852         |            2             |           1            |            36              |       178        |
|       ...          |           ...            |          ...           |           ...              |       ...        |


- \( x_j \) = j·µó ∞ feature  
- \( n = 4 \) = number of features  
- \( \vec{x}^{(i)} \) = features of the i·µó ∞ training example  
- \( x_j^{(i)} \) = value of feature \( j \) in the i·µó ∞ training example  

### üü¶ Example from the table:

- \( i = 2 \) ‚Üí second training example  
- \( \vec{x}^{(2)} = [1416,\ 3,\ 2,\ 40] \)  
- \( x_3^{(2)} = 2 \)


---

# üß† Model Definition

- **Old model (1 feature)**:
  \[
  f_{w,b}(x) = wx + b
  \]

- **New model (n features)**:
  \[
  f_{w,b}(x) = w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + \dots + w‚Çôx‚Çô + b
  \]

- **Compact vector notation using dot product**:
  \[
  f_{w,b}(x) = \vec{w} \cdot \vec{x} + b
  \]


> Dot Product
>\[
>\vec{w} \cdot \vec{x} = \sum_{j=1}^{n} w_j x_j
>\]


# üè† Example Interpretation (House Prices)

\[
f(x) = 0.1x‚ÇÅ + 4x‚ÇÇ + 10x‚ÇÉ - 2x‚ÇÑ + 80
\]

- `0.1`: price increases by $100 per square foot
- `4`: price increases by $4,000 per bedroom
- `10`: price increases by $10,000 per floor
- `-2`: price **decreases** by $2,000 per year of age
- `80`: base price in $1,000s (i.e., $80,000)


# ‚ö° Vectorization 
## Parameters and Features

\[
\vec{w} = [w_1, w_2, w_3] \quad \text{with } n = 3
\]

\[
b \text{ is a number}
\]

\[
\vec{x} = [x_1, x_2, x_3]
\]

**Note:**

- Linear algebra counts from **1**.
- Code (NumPy/Python) counts from **0**.

```python
w = np.array([1.0, 2.5, -3.3])
b = 4
x = np.array([10, 20, 30])
```

---

## Without Vectorization

\[
f_{\vec{w}, b}(\vec{x}) = \sum_{j=1}^{n} w_j x_j + b
\]



 Without Vectorization (Expanded Formula, \( n = 100{,}000 \))

\[
f_{\vec{w}, b}(\vec{x}) = w_1 x_1 + w_2 x_2 + w_3 x_3 + b
\]

```python
f = w[0] * x[0] + 
    w[1] * x[1] + 
    w[2] * x[2] + b
```

üò¢ Manual, repetitive, and error-prone

In Python:

```python
f = 0
for j in range(0, n):  # j = 0 to n-1
    f = f + w[j] * x[j]
f = f + b
```
## Vectorization (Efficient Way)

\[
f_{\vec{w}, b}(\vec{x}) = \vec{w} \cdot \vec{x} + b
\]

```python
f = np.dot(w, x) + b
```

üòÄ Clean and fast with NumPy


- **Vectorization** is a technique to make code:
  - **Shorter** (easier to read/write)
  - **Faster** (more computationally efficient)
- Uses **linear algebra operations** and libraries like **NumPy**
- Can take advantage of **parallel hardware** like **CPUs** and **GPUs**

---
## Without Vectorization

```python
for j in range(0, 16):
    f = f + w[j] * x[j]
```

At different time steps:

- \( t_0 \): \( f + w[0] \cdot x[0] \)
- \( t_1 \): \( f + w[1] \cdot x[1] \)
- ...
- \( t_{15} \): \( f + w[15] \cdot x[15] \)

‚ö†Ô∏è **Sequential**, not optimized


## Vectorization

```python
np.dot(w, x)
```

### Computation flow:

\[
\begin{align*}
\text{At } t_0: & \quad 
\begin{bmatrix}
w[0] & w[1] & \dots & w[15]
\end{bmatrix}
\times
\begin{bmatrix}
x[0] \\ x[1] \\ \vdots \\ x[15]
\end{bmatrix}
\quad \text{(in parallel)}
\\[10pt]
\text{At } t_1: & \quad 
w[0] \cdot x[0] + w[1] \cdot x[1] + \dots + w[15] \cdot x[15]
\end{align*}
\]

‚úÖ **Efficient ‚Üí scales to large datasets**
# üßæ Gradient descent

## Gradient Descent

\[
\vec{w} = (w_1, w_2, \ldots, w_{16}) \quad \text{(parameters)}
\]
\[
\vec{d} = (d_1, d_2, \ldots, d_{16}) \quad \text{(derivatives)}
\]

```python
w = np.array([0.5, 1.3, ..., 3.4])
d = np.array([0.3, 0.2, ..., 0.4])
```

### Compute:

\[
w_j = w_j - 0.1 \cdot d_j \quad \text{for } j = 1 \ldots 16
\]

üìù `0.1` is the **learning rate** \( \alpha \)


### Without Vectorization

\[
\begin{align*}
w_1 &= w_1 - 0.1 d_1 \\
w_2 &= w_2 - 0.1 d_2 \\
&\vdots \\
w_{16} &= w_{16} - 0.1 d_{16}
\end{align*}
\]

```python
for j in range(0, 16):
    w[j] = w[j] - 0.1 * d[j]
```

### With Vectorization

\[
\vec{w} = \vec{w} - 0.1 \cdot \vec{d}
\]

```python
w = w - 0.1 * d
```

‚û°Ô∏è Performs the operation on all elements **in parallel** ‚Üí ‚úÖ **Efficient for large models**

# üî¢ Multiple Linear Regression & Vectorization ‚Äì Summary

## üìå Model Representation

- **Parameters**:  
  Instead of individual weights \( w_1, w_2, \ldots, w_n \), group them into a vector \( \vec{w} \).

- **Prediction Function**:  
  \[
  f_{\vec{w}, b}(\vec{x}) = \vec{w} \cdot \vec{x} + b
  \]

---
# Gradient descent for multiple regression


| Concept             | Previous Notation                                                                 | Vector Notation                                                                 |
|---------------------|-----------------------------------------------------------------------------------|----------------------------------------------------------------------------------|
| **Parameters**       | \( w_1, \cdots, w_n \), \( b \)                                                  | \( \vec{w} = [w_1, \cdots, w_n] \), \( b \) still a number                       |
| **Model**            | \( f_{\vec{w}, b}(\vec{x}) = w_1 x_1 + \cdots + w_n x_n + b \)                   | \( f_{\vec{w}, b}(\vec{x}) = \vec{w} \cdot \vec{x} + b \) *(dot product)*        |
| **Cost Function**    | \( J(w_1, \cdots, w_n, b) \)                                                     | \( J(\vec{w}, b) \)                                                              |
| **Gradient Descent** | repeat {<br> \( w_j = w_j - \alpha \frac{\partial}{\partial w_j} J(w_1, \cdots, w_n, b) \) <br> \( b = b - \alpha \frac{\partial}{\partial b} J(w_1, \cdots, w_n, b) \) <br>} | repeat {<br> \( w_j = w_j - \alpha \frac{\partial}{\partial w_j} J(\vec{w}, b) \) <br> \( b = b - \alpha \frac{\partial}{\partial b} J(\vec{w}, b) \) <br>} |


| Gradient Descent      | One Feature (n = 1)                                                                                          | Multiple Features (n ‚â• 2)                                                                                                 |
|-----------------------|-------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|
| **Weight Update**     | \( w = w - \alpha \cdot \frac{1}{m} \sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)}) \cdot x^{(i)} \)             | For each \( j = 1 \) to \( n \):<br>\( w_j = w_j - \alpha \cdot \frac{1}{m} \sum_{i=1}^{m} (f_{\vec{w},b}(\vec{x}^{(i)}) - y^{(i)}) \cdot x_j^{(i)} \) |
| **Bias Update**       | \( b = b - \alpha \cdot \frac{1}{m} \sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)}) \)                          | \( b = b - \alpha \cdot \frac{1}{m} \sum_{i=1}^{m} (f_{\vec{w},b}(\vec{x}^{(i)}) - y^{(i)}) \)                              |
| **Update Rule**       | Simultaneously update \( w \) and \( b \)                                                                   | Simultaneously update all \( w_j \) (for \( j = 1, \dots, n \)) and \( b \)                                               |
| **Gradient Form**     | \( \frac{\partial}{\partial w} J(w, b) \)                                                                   | \( \frac{\partial}{\partial w_j} J(\vec{w}, b) \)                                                                         |


# üìå An Alternative to Gradient Descent

## [Normal Equation](./normal-equation.md)

- Only for **linear regression**
- Solves for parameters **w** and **b** without iterations

### Disadvantages

- Doesn‚Äôt generalize to other learning algorithms  
- Slow when the number of features is large (**> 10,000**)

## üí° What You Need to Know

- The **normal equation method** may be used in some machine learning libraries that implement linear regression.
- **Gradient descent** is the **recommended method** for finding parameters \( w, b \) in most cases.

> **Normal Equation** is a mathematical method used to find the parameters of a Linear Regression model without using iterations.
---

# Feature Scaling
This example demonstrates how the **scale of input features** affects the **model parameters** and the behavior of **gradient descent**.

![alt text](image-7.png)
---

# üè† Feature and Parameter Values

## üìå Model Formula
```code
price = w‚ÇÅ¬∑x‚ÇÅ + w‚ÇÇ¬∑x‚ÇÇ + b
```
- **x‚ÇÅ**: size (in feet¬≤), range: `300‚Äì2000` ‚Üí large  
- **x‚ÇÇ**: number of bedrooms, range: `0‚Äì5` ‚Üí small

## üè° One Training Example
x‚ÇÅ = 2000, x‚ÇÇ = 5, price = $500k
```code
price = w‚ÇÅ¬∑2000 + w‚ÇÇ¬∑5 + b
```

## üìè Size of the Parameters `w‚ÇÅ`, `w‚ÇÇ`?

## üìä Comparison of Parameter Scenarios (Transposed)

|                         | **Unbalanced Parameters**                           | **Reasonable Parameters**                          |
|-------------------------|-----------------------------------------------------|----------------------------------------------------|
| **Parameters**          | \( w_1 = 50 \)<br>,\( w_2 = 0.1 \)<br>,\( b = 50 \)       | \( w_1 = 0.1 \)<br>,\( w_2 = 50 \)<br>,\( b = 50 \)      |
| **Prediction Formula**  | \( 50 \cdot 2000 + 0.1 \cdot 5 + 50 \)              | \( 0.1 \cdot 2000 + 50 \cdot 5 + 50 \)             |
| **Computation Result**  | \( 100{,}000K + 0.5K + 50K = 100{,}050.5K \)        | \( 200K + 250K + 50K = 500K \)                     |
| **Outcome**             | - **Way too high** ‚Üí overestimation <br>- **Poor parameter choice** due to unscaled features | ‚úÖ Accurate ‚Äì matches true <br> - **More reasonable parameter values** due to awareness of feature rangeprice                  |

---

## üß† Insight: Feature Ranges Affect Parameter Magnitude

- Large-range feature (like size) ‚Üí smaller weight
- Small-range feature (like bedrooms) ‚Üí larger weight

This mismatch can distort the cost function and affect learning.

---

## üöÄ Why Feature Scaling Matters
![alt text](image-8.png)

### üî∂ Feature Space (Input Features)

#### üî∏ Top-left (Unscaled Features)

- Features:
  - `x‚ÇÅ`: size in ft¬≤ (ranging from 300 to 2000)
  - `x‚ÇÇ`: number of bedrooms (ranging from 0 to 5)
- The two features have very different ranges.
- This causes the scatterplot to be stretched along the x-axis and compressed along the y-axis.
- As a result, gradient descent may converge slowly or inefficiently.

#### üî∏ Bottom-left (Rescaled Features)

- The same features are **rescaled** to similar ranges, typically from 0 to 1.
- Both `x‚ÇÅ` and `x‚ÇÇ` are normalized so that their magnitudes are comparable.
- The data points become more evenly distributed.
- Gradient descent becomes more stable and converges faster.

---

# üìè Feature Scaling

Feature scaling is used to bring features with very different ranges into similar scales, which helps **gradient descent converge faster** and more reliably.

---

## üßÆ Methods of Feature Scaling

### 1. **Rescaling (Min-Max Normalization)**
- Divide each feature value by its maximum or minimum value .
- Formula:
\[
x_{\text{norm}} = \frac{x}{x_{\text{max}}}
\quad \text{or} \quad
x_{\text{norm}} = \frac{x}{x_{\text{min}}}
\]

- Example:
  - `x‚ÇÅ ‚àà [300, 2000] ‚Üí x‚ÇÅ_scaled = x‚ÇÅ / 2000`
  - `x‚ÇÇ ‚àà [0, 5] ‚Üí x‚ÇÇ_scaled = x‚ÇÇ / 5`
- Resulting scaled features fall within `[0, 1]`

---

### 2. **Mean Normalization**
![alt text](image-9.png)
- Centers features around 0 by subtracting the mean.
- Formula:
  \[
  x_{\text{norm}} = \frac{x - \mu}{\text{max} - \text{min}}
  \]

- Example:
  - `x‚ÇÅ ‚Üí Œº = 600`, range = 300‚Äì2000  
    ‚Üí `x‚ÇÅ_normalized ‚àà [-0.18, 0.82]`
  - `x‚ÇÇ ‚Üí Œº = 2.3`, range = 0‚Äì5  
    ‚Üí `x‚ÇÇ_normalized ‚àà [-0.46, 0.54]`

---

# üîÅ Gradient Descent Convergence

## üß† How to Know if Gradient Descent is Working?

Gradient descent aims to find parameters **w** and **b** that minimize the cost function **J(w, b)**. To evaluate if it‚Äôs converging properly:


## üìà Plot the Cost Function Over Iterations
![alt text](image-12.png)

- Plot **J(w, b)** on the **vertical axis**
- Plot **number of iterations** on the **horizontal axis**
- This is called a **learning curve**

If gradient descent is working well:
- **J should decrease** with every iteration
- The curve should eventually **flatten**, indicating convergence

---

## üö® What If J Increases?

- Could mean:
  - üî∫ **Learning rate Œ± is too large**
  - üêû **Bug** in the implementation

---


## ‚è≥ When Has It Converged?

- If **J stops decreasing significantly**, gradient descent has likely converged
- Example: after 300‚Äì400 iterations, curve flattens

> Convergence speed varies by application:
> - Some may converge in **30 iterations**
> - Others may need **100,000+ iterations**

---

## üß™ Automatic Convergence Test
This section explains a simple and practical test to automatically determine if gradient descent has converged, using a small number called epsilon (Œµ).

### üîç What is Œµ (epsilon)?

- **Epsilon (Œµ)** is a small positive number used as a **threshold** for detecting convergence.
- Common value:  
  \[
  \varepsilon = 10^{-3} = 0.001
  \]


### ‚úÖ Convergence Condition

During gradient descent, you compute the cost function \( J(w, b) \) at each iteration.

If the **change in cost** between two successive iterations is **less than or equal to Œµ**, we declare that gradient descent has **converged**:

\[
|J^{(i)} - J^{(i-1)}| \leq \varepsilon \quad \Rightarrow \quad \text{converged}
\]

> This means gradient descent is no longer making significant improvements and has likely reached or approached the minimum of the cost function.

### üß† Why This Works

- A small change in cost means the gradient is very small, and updates to parameters are minimal.
- This typically happens when gradient descent is near a **local or global minimum**.
- If updates aren‚Äôt helping much, there‚Äôs no need to keep running ‚Äî we can safely stop.

### üß∑ When to Use It

- Useful in **automated training pipelines** to stop training without manual checks.
- Saves time when working with large models or datasets that require thousands of iterations.
- However, it's still good practice to **visually inspect the learning curve** to verify proper convergence and spot any unexpected behavior.


### üîö Summary

- Use Œµ (epsilon) to define how small the cost improvement must be to stop.
- If cost doesn‚Äôt decrease significantly: **stop training**.
- It‚Äôs a simple and effective method to detect **convergence**.
- Combine with **learning curve plots** for better reliability.


## üéØ Key Takeaways
- Always monitor J vs. iterations
- If curve flattens ‚Üí likely converged
- If J increases ‚Üí check Œ± or code
- Use visual inspection over automated tests for better insight

# üöÄ Choosing a Good Learning Rate (Œ±)
![alt text](image-13.png)
![alt text](image-14.png)

Your learning algorithm's performance greatly depends on the **learning rate (Œ±)**. Choosing it properly ensures **faster and stable convergence**. Here's how to do it:

---

## ‚ö†Ô∏è What Happens with a Bad Learning Rate?

### Too Small (Œ± is too low):
- Gradient descent runs **very slowly**
- Takes a large number of iterations to converge

### Too Large (Œ± is too high):
- **Cost function may increase** instead of decrease
- Gradient descent might **never converge**
- Can cause **oscillation** or **divergence**

---

## üìà Diagnosing with the Cost Plot

- If the cost **goes up and down**, gradient descent is likely **not working**.
- This may be due to:
  - ‚ùå A bug in the code
  - üö´ Learning rate too large

---

## üéØ Understanding the Overshoot Problem

- Imagine cost \( J(w_1) \) vs. parameter \( w_1 \)
- A large Œ± can cause updates to **overshoot** the minimum:
  - Jumping back and forth across the minimum
  - Failing to settle down

---

## üõ†Ô∏è Debugging Tip

- Try setting **Œ± to a very small value**
- If cost **still doesn‚Äôt decrease every iteration**, it likely means:
  - ‚ö†Ô∏è There‚Äôs a **bug in the implementation**

### Example of a bug:
```python
# Wrong:
w1 = w1 + Œ± * derivative  # This increases cost

# Correct:
w1 = w1 - Œ± * derivative  # This decreases cost
```
## üîç Practical Strategy to Choose Œ±
1. Try multiple values of Œ±

- Start with 0.001
- Then try ~3√ó larger values:
- 0.003, 0.03, 0.3 etc.

2. For each value:
- Run gradient descent for a few iterations
- Plot the cost function vs. iterations

3. Pick the best Œ±:
- Look for fast and smooth decrease in cost
- Avoid overshooting or flat (slow) curves

4. Tip:

- Try values until you find one that‚Äôs too small
- Then go up until you find one that‚Äôs too large
- Choose something slightly smaller than the largest reasonable value

## ‚úÖ Summary

| Learning Rate Œ± | Behavior                       |
| --------------- | ------------------------------ |
| Too Small       | Converges very slowly          |
| Too Large       | May diverge or oscillate       |
| Just Right      | Smooth, rapid decrease in cost |



# Choosing the Learning Rate (Œ±) for Gradient Descent

## Key Principles
- **Goldilocks Principle**:
  - Œ± too small ‚Üí Slow convergence
  - Œ± too large ‚Üí Divergence (cost increases)
  - Œ± just right ‚Üí Efficient convergence

## Diagnostic Signs
| Observation | Likely Issue | Action |
|-------------|--------------|--------|
| Cost oscillates | Œ± slightly too large | Reduce Œ± by 3x |
| Cost consistently increases | Œ± too large or sign error in code | Check code & reduce Œ± |
| Cost decreases very slowly | Œ± too small | Increase Œ± gradually |

# Practical Workflow
1. Initialize with Œ±=0.01
2. Monitor learning curve:
- Good: Steady exponential decay
- Bad: Oscillations/plateaus
3. Adjust using 3x rule:
- Too slow? Try 3x larger Œ±
- Oscillating? Try Œ±/3




































# üßæ Terminology

- **Multiple Linear Regression**: Linear regression with **multiple input features**
- **Univariate Regression**: Linear regression with a **single feature**
- Note: **"Multivariate regression"** refers to a different concept (not used here)

